func,target,cwe,project,commit_id,hash,size,message
"    def likeComments(self,commentid,userid):
        sqlText=""insert into comment_like values(%d,%d);""%(userid,commentid)
        result=sql.insertDB(self.conn,sqlText)
        return result;",1,cwe-089,,,,,
"    def add_inverters(self):
        interfaces = self.config.get_connection_interfaces()
        for source in interfaces:
            if source[""type""] == ""inverter"":

                query = '''
                    INSERT OR IGNORE INTO Inverters (
                        Serial,
                        EToday,
                        ETotal
                    ) VALUES (
                        %s,
                        %s,
                        %s
                    );
                ''' % (source[""serial_id""], 0, source[""prev_etotal""])
                self.c.execute(query)

                query = '''
                    UPDATE Inverters
                    SET     
                        Name='%s', 
                        Type='%s', 
                        SW_Version='%s', 
                        Status='%s',
                        TimeStamp='%s'
                    WHERE Serial='%s';
                ''' % (source[""name""], source[""inverter_type""], ""s0-bridge v0"", ""OK"", int(datetime.now().timestamp()), source[""serial_id""] )
                self.c.execute(query)

                self.db.commit()",1,cwe-089,,,,,
"@mod.route('/delete/<int:msg_id>', methods=['GET', 'POST'])
def delete(msg_id):
    if request.method == 'GET':
        sql = ""DELETE FROM message where msg_id = '%d';"" % (msg_id)
        cursor.execute(sql)
        conn.commit()
        flash('Delete Success!')
    return redirect(url_for('show_entries'))",1,cwe-089,,,,,
"def karma_rank(name):
    db = db_connect()
    cursor = db.cursor()
    try:
        cursor.execute('''
            SELECT (SELECT COUNT(*) FROM people AS t2 WHERE t2.karma > t1.karma)
            AS row_Num FROM people AS t1 WHERE name='{}'
        '''.format(name))
        rank = cursor.fetchone()[0] + 1
        logger.debug('Rank of {} found for name {}'.format(rank, name))
        db.close()
        return rank
    except Exception as e:
        logger.error('Execution failed with error: {}'.format(e))
        raise",1,cwe-089,,,,,
"def get_last_month(db, scene):
    sql = ""select date from matches where scene='{}' order by date desc limit 1;"".format(scene)
    res = db.exec(sql)
    date = res[0][0]

    # If it has been more than 1 month since this last tournament,
    # go ahead and round this date up by a 1 month
    # eg, if the last tournament was 2015-01-15 (a long time ago)
    # we can assume the scene won't have more tournaments
    # So just round to 2015-02-01
    today = datetime.datetime.today().strftime('%Y-%m-%d')
    y, m, d = today.split('-')
    cy, cm, cd = date.split('-')
    if y > cy or m > cm:
        # Add 1 to the month before we return
        # eg 2018-03-01 -> 2018-04-01
        date = get_next_month(date)

    return date",1,cwe-089,,,,,
"@app.route('/players/<int:player_id>/achievements')
def achievements_list_player(player_id):
    """"""Lists the progress of achievements for a player.

    :param player_id: ID of the player.

    :return:
        If successful, this method returns a response body with the following structure::

            {
              ""items"": [
                {
                  ""achievement_id"": string,
                  ""state"": string,
                  ""current_steps"": integer,
                  ""create_time"": long,
                  ""update_time"": long
                }
              ]
            }
    """"""
    with db.connection:
        cursor = db.connection.cursor(db.pymysql.cursors.DictCursor)
        cursor.execute(""""""SELECT
                            achievement_id,
                            current_steps,
                            state,
                            UNIX_TIMESTAMP(create_time) as create_time,
                            UNIX_TIMESTAMP(update_time) as update_time
                        FROM player_achievements
                        WHERE player_id = '%s'"""""" % player_id)

        return flask.jsonify(items=cursor.fetchall())",1,cwe-089,,,,,
"    def check_if_this_project_is_in_database(self, project_id):
        self.cursor.execute(""SELECT count(id) FROM projects where id = %s"" % project_id)
        return self.cursor.fetchall()[0][0] == 1",1,cwe-089,,,,,
"@app.route(""/<page_name>/edit"")
def edit_page(page_name):
    query = db.query(""select * from page where title = '%s'"" % page_name).namedresult()
    if len(query) == 0:
        return render_template(
            ""edit.html"",
            page_name=page_name,
            query=query
        )
    else:
        return render_template(
            ""edit.html"",
            page_name=page_name,
            query=query[0]
        )",1,cwe-089,,,,,
"def reportMatch(winner, loser):
    """"""Records the outcome of a single match between two players.

    Args:
      winner:  the id number of the player who won
      loser:  the id number of the player who lost
    """"""
    conn = connect()
    cursor = conn.cursor()
    cursor.execute(""INSERT INTO playsRecord (winner, loser) VALUES ('%s', '%s')"" % (winner, loser));
    conn.commit()
    conn.close()",1,cwe-089,,,,,
"def get_game_info(conn, game):
    # get the basic game properties
    cursor = conn.cursor()
    cursor.execute(""SELECT player1,player2,size,state FROM games WHERE id = %d;"" % game)
    if cursor.rowcount != 1:
        raise FormError(""Invalid game ID"")

    row = cursor.fetchall()[0]
    players = [row[0],row[1]]
    size    =  row[2]
    state   =  row[3]

    if state is None:
         state = ""Active""

    cursor.close()

    return (players,size,state)",1,cwe-089,,,,,
"def process_as_reply(email_obj):
    job_number = email_obj['subject'].split(': #')[1]
    feedback = re.findall(""^[\W]*([Oo\d]){1}(?=[\W]*)"", email_obj['content'].replace('#','').replace('link', ''))[0]
    feedback = int(0 if feedback == ('O' or 'o') else feedback)
    dcn_key = re.findall('\w{8}-\w{4}-\w{4}-\w{4}-\w{12}', email_obj['content'])[0]
    logger.info(f""got feedback `{feedback}` for job #`{job_number}`"")
    with create_connection() as conn:
        was_prev_closed = pd.read_sql(f""SELECT * FROM df_dilfo WHERE job_number={job_number}"", conn).iloc[0].closed
    if was_prev_closed:
        logger.info(f""job was already matched successfully and logged as `closed`... skipping."")
        return
    if feedback == 1:
        logger.info(f""got feeback that DCN key {dcn_key} was correct"")
        update_status_query = ""UPDATE df_dilfo SET closed = 1 WHERE job_number = {}""
        with create_connection() as conn:
            conn.cursor().execute(update_status_query.format(job_number))
        logger.info(f""updated df_dilfo to show `closed` status for job #{job_number}"")
    with create_connection() as conn:
        df = pd.read_sql(""SELECT * FROM df_matched"", conn)
        match_dict_input = {
            'job_number': job_number,
            'dcn_key': dcn_key,
            'ground_truth': 1 if feedback == 1 else 0,
            'multi_phase': 1 if feedback == 2 else 0,
            'verifier': email_obj[""sender""],
            'source': 'feedback',
            'log_date': str(datetime.datetime.now().date()),
            'validate': 0,
        }
        df = df.append(match_dict_input, ignore_index=True)
        df = df.drop_duplicates(subset=[""job_number"", ""dcn_key""], keep='last')
        df.to_sql('df_matched', conn, if_exists='replace', index=False)
        logger.info(
            f""DCN key `{dcn_key}` was a ""
            f""{'successful match' if feedback == 1 else 'mis-match'} for job ""
            f""#{job_number}""
        )",1,cwe-089,,,,,
"def update_playlist(id, name, db):
    db.execute(
        ""UPDATE playlist SET name='{name}' WHERE id={id};"".format(name=name, id=id))",1,cwe-089,,,,,
"    def get_requested_month(self, date):
        data = dict()

        month_start, month_end = self.get_epoch_month(date)
        data['interval'] = {'from': self.convert_local_ts_to_utc(month_start, self.local_timezone), 'to': self.convert_local_ts_to_utc(month_end, self.local_timezone)}
        month_total = 0

        query = '''
            SELECT TimeStamp, SUM(DayYield) AS Power 
            FROM MonthData 
            WHERE TimeStamp BETWEEN %s AND %s
            GROUP BY TimeStamp
            '''

        data['data'] = list()
        for row in self.c.execute(query % (month_start, month_end)):
            data['data'].append({'time': self.convert_local_ts_to_utc(row[0], self.local_timezone), 'power': row[1]})
            month_total += row[1]

        data['total'] = month_total

        query = '''
            SELECT MIN(TimeStamp) as Min, MAX(TimeStamp) as Max 
            FROM ( SELECT TimeStamp FROM MonthData GROUP BY TimeStamp );
            '''

        self.c.execute(query)
        first_data, last_data = self.c.fetchone()

        if first_data: data['hasPrevious'] = (first_data < month_start)
        else: data['hasPrevious'] = False
        if last_data: data['hasNext'] = (last_data > month_end)
        else: data['hasNext'] = False

        return data",1,cwe-089,,,,,
"def retrieve_videos_from_playlist(playlist_id, db):
    db.execute(""SELECT id, title, thumbnail, position from video WHERE playlist_id={playlist_id} ORDER BY position ASC;"".format(
        playlist_id=playlist_id))
    rows = db.fetchall()
    return rows",1,cwe-089,,,,,
"def create_playlist(name):
    db = connect_to_database()
    cursor = db.cursor()
    cursor.execute(
        ""INSERT INTO playlist (name, video_position) VALUES('{name}', 0);"".format(name=name))
    db.commit()
    db.close()",1,cwe-089,,,,,
"def update_video_positions(removed_position, db):
    db.execute(""UPDATE video SET position = position - 1 WHERE position > {removed_position}"".format(
        removed_position=removed_position))",1,cwe-089,,,,,
"    @staticmethod
    def _check_camera_tags(tags):
        """"""
        Function that convert stupid code name of a smartphone or camera
        from EXIF to meaningful one by looking a collation in a special MySQL
        table For example instead of just Nikon there can be
        NIKON CORPORATION in EXIF

        :param tags: name of a camera and lens from EXIF
        :return: list with one or two strings which are name of
        camera and/or lens. If there is not better name for the gadget
        in database, function just returns name how it is
        """"""
        checked_tags = []

        for tag in tags:
            if tag:  # If there was this information inside EXIF of the photo
                tag = str(tag).strip()
                log.info('Looking up collation for %s', tag)
                query = ('SELECT right_tag '
                         'FROM tag_table '
                         'WHERE wrong_tag=""{}""'.format(tag))
                cursor = db.execute_query(query)
                if not cursor:
                    log.error(""Can't check the tag because of the db error"")
                    log.warning(""Tag will stay as is."")
                    continue
                if cursor.rowcount:
                    # Get appropriate tag from the table
                    tag = cursor.fetchone()[0]
                    log.info('Tag after looking up in tag_tables - %s.', tag)

            checked_tags.append(tag)
        return checked_tags",1,cwe-089,,,,,
"	def add_input(self, data):
		connection = self.connect()
		try:
			# The following introduces a deliberate security flaw.See section on SQL injection below
			query = ""INSERT INTO crimes (description) VALUES('{}');"".format(data)
			with connection.cursor() as cursor:
				cursor.execute(query)
				connection.commit()
		finally:
			connection.close()",1,cwe-089,,,,,
"def getResults(poll_name):
    conn, c = connectDB()
    req = ""SELECT options from {} where name = '{}'"".format(CFG(""poll_table_name""), poll_name)
    options_str = queryOne(c, req)

    if not options_str:
        raise LookupError(""Poll '{}' not found in DB"".format(poll_name))

    total = 0
    options = options_str.split("","")
    results = dict()
    for opt in options:
        count = getOptionCount(c, poll_name, opt)
        total += int(count)
        results.update({opt:count})

    conn.close()
    return (results, total)",1,cwe-089,,,,,
"def update_sources(conn, sqlite, k10plus, ai):
    """"""
    Update the source table.
    """"""
    current_sources = get_all_current_sources(k10plus, ai)
    old_sources = get_all_old_sources(conn, sqlite)

    # Check if the source table is allready filled and this is not the first checkup
    source_table_is_filled = len(old_sources) > 100

    for old_source in old_sources:
        if source_table_is_filled and old_source not in current_sources:
            message = ""Die SID %s ist im aktuellen Import nicht mehr vorhanden.\nWenn dies beabsichtigt ist, bitte die SID aus der Datenbank loeschen."" % old_source
            send_message(message)

    for current_source in current_sources:
        if current_source not in old_sources:
            message = ""The source %s is new in Solr."" % current_source
            if source_table_is_filled:
                send_message(message)
            else:
                logging.info(message)
            sql = ""INSERT INTO source (source) VALUES (%s)"" % current_source
            sqlite.execute(sql)
            conn.commit()",1,cwe-089,,,,,
